---
title: TIL001
categories: TIL
tags: big_data
toc: true
toc_sticky: true
---

## 1. Hadoop

### 1-1 개념

- 분산 환경에서 빅데이터를 처리하는 오픈소스 프레임워크.
- Scalability를 높이기 위해서 HDD 손상 등을 당연히 있는 일로 간주하고 실패를 책임지도록 설계함. 따라서 저렴한 하드웨어로도 안정적인 시스템을 구축할 수 있음.
- 분산 파일 시스템, 리소스 관리자, 분산 데이터처리 프레임워크 등의 요소로 구성.

### 1-2 구성 요소

![image-20220124002751249](https://raw.githubusercontent.com/chun1000/2022-image-repo/image/image-20220124002751249.png)

- 하둡은 저장소로 HDFS를 주로 사용함. HDFS는 데이터를 여러 랙에 분산 저장하는 전략을 지님.
- YARN은 하둡의 리소스 관리자. 데이터 지역성을 높여주고 계산량이 많은 어플리케이션이 리소스를 독점하지 않도록 제어.
- 리소스는 컨테이너로 분리되며, 컨테이너는 CPU 코어와 메모리 용량으로 분리됨. YARN은 실행 중인 컨테이너를 모니터링함.
- 분산 데이터 처리에는 MapReduce가 있음. 합계/평균/계수 등에 유리하지만 반복적 작업에서는 비효율 적.

### 1-3 Hive

- Hadoop의 데이터를 SQL로 분석하는 용도로 개발됨.

## 2. HDFS

- 파일은 블록으로 쪼개짐. 쪼개진 블록들은 여러 노드에 복사 분산됨.
- 데이터 노드는 주기적으로 노드에 저장된 블록 정보 전송.
- 네임 노드는 데이터 노드가 정상 동작하는지 확인.
- 클라이언트는 네임노드에서 원하는 정보를 조회 가능함.

### 2-1. HDFS 저장 과정

![image-20220124002929025](https://raw.githubusercontent.com/chun1000/2022-image-repo/image/image-20220124002929025.png)

1) HDFS 클라이언트에 저장 요청이 들어옴.
2) 경로 생성 후 Lock이 걸리고 데이터 노드 목록 반환.
3) 클라이언트가 첫 번째 데이터 노드에 데이터 블록 전송.
4) 첫 번째 데이터 노드는 데이터를 저장, 두 번째 데이터 노드로 전송.
5) 두 번째 데이터 노드도 같은 동작을 수행.
6) 각 노드는 데이터를 자신에게 넘겨준 노드에 저장이 완료됐다고 응답.
7) 첫 번째 노드는 응답을 받으면 클라이언트에게 파일 저장이 완료됐다는 응답을 보냄.

### 2-2 . HDFS 읽기 과정

![image-20220124002859367](https://raw.githubusercontent.com/chun1000/2022-image-repo/image/image-20220124002859367.png)

- 클라이언트에 읽기 요청이 들어옴.
- 네임 노드에 정보를 요청해서 블록 리스트를 얻음.
- 클라이언트가 데이터 노드에 블록을 요청, 데이터 노드는 블록을 전송.
- 어플리케이션에 회수한 데이터를 전달함.

## 3. Map-Reduce

### 3-1. 개념

- 대용량의 데이터를 분산 처리하기 위한 모델. 큰 데이터를 블록 단위로 쪼개서 Map Reduce를 거침.

### 3-2. 과정

![image-20220124003037688](https://raw.githubusercontent.com/chun1000/2022-image-repo/image/image-20220124003037688.png)

1. Split에서 Input을 쪼갬.
2. Mapping에서 Input을 Key-value 쌍으로 변환.
3. Shuffling에서 같은 키를 가지는 데이터를 묶음.
4. Reducer에서 최종 결과를 산출.

## 4. Spark

- Spark는 빠른 속도의 분산 인메모리 프로세스 엔진.
- HDFS에 저장된 데이터를 하둡 코어 라이브러리를 통해서 메모리에 불러올 수 있음.
- MapReduce는 대규모 데이터 일괄 처리에는 강점이 있지만, 저지연이나 반복 연산에는 약함. Spark는 데이터 분산 메모리 캐싱을 통해 빠른 반응 속도를 보여줄 수 있음.

## 5. Schema-on

- Schema-on-read: 입수한 데이터를 런타임에 해석하는 것.
- 데이터 웨어하우스는 사전에 정의된 스키마이며 데이터 변환 작업이 적재 전에 필요함. 이러한 데이터 입수 단계를 ETL(Extraction-Transformation-Loading)이라 부르며, ETL에는 큰 노력과 비용이 소모 됨.
- 데이터 레이크는 모든 데이터를 원시 형식으로 저장하는 중앙 저장소를 의미. 이런 방식은 Schema-on-read로 볼 수 있으며, 원시 데이터에 자신이 원하는 구조를 적용 가능함.
- 데이터 웨어하우스는 반대로 Schema-on-Write로 볼 수 있음. 이러한 방식은 데이터를 어떻게 활용할 지 사전에 추측해야함. 